{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "subfolder_path = os.path.abspath(\"audiocraft\")\n",
    "sys.path.append(subfolder_path)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "#from transformers import AutoProcessor, MusicgenMelodyForConditionalGeneration\n",
    "\n",
    "import torchaudio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "from audiocraft.utils import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is for loading the trained models into the audiocraft module for using them to generate music with the python package\n",
    "model_name = 'with_submixes_25ep'\n",
    "export.export_lm(f'/home/sd3705/music_gen_2024f/audiocraft_output_sd3705/xps/{model_name}/checkpoint.th', f'../audiocraft/checkpoints/{model_name}/state_dict.bin')\n",
    "export.export_pretrained_compression_model('facebook/encodec_32khz', f'../audiocraft/checkpoints/{model_name}/compression_state_dict.bin')\n",
    "\n",
    "model_name = 'with_submixes_description_25ep'\n",
    "export.export_lm(f'/home/sd3705/music_gen_2024f/audiocraft_output_sd3705/xps/{model_name}/checkpoint.th', f'../audiocraft/checkpoints/{model_name}/state_dict.bin')\n",
    "export.export_pretrained_compression_model('facebook/encodec_32khz', f'../audiocraft/checkpoints/{model_name}/compression_state_dict.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52989fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "slakh_path = \"/engram/naplab/shared/Slakh2100/slakh2100_flac_redux\" #Dataset path is defined (this should be edited to run in another machine)\n",
    "track_path = \"test/Track01881\" #One track from the test set is chosen to use as the reference track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c7475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aud_input, sr = torchaudio.load(os.path.join(slakh_path,track_path,'stems','S02.flac')) #The acoustic piano channel of the chosen track is loaded\n",
    "aud_input = aud_input[:,int(sr*1.5):int(sr*11.5)] #Only the 10 seconds of the track is used\n",
    "aud_input_repeated = aud_input.unsqueeze(1)\n",
    "display_audio(aud_input,sample_rate=sr) #Audio is displayed to play in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32975c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Samples/Final' #Folder to save audios for demo\n",
    "aud_input_save = aud_input.to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,\"reference.wav\"), aud_input_save, sr) #Reference track is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(slakh_path,track_path,'stems','S02.json'), 'r') as metadata_file:\n",
    "    curr_json = json.load(metadata_file) #.json file for the reference track is loaded for the description\n",
    "description = curr_json['description']\n",
    "description = ''.join(description.split('. ')[1:]) #Instruments are discarded from the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First instrument group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0fc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = ('Electric Guitar (Clean)','Acoustic Grand Piano','Drum','Choir (aahs)') #New instruments are defined\n",
    "instruments = ', '.join(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b514b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452cbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'original' #Model name is defined (baseline model)\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-melody') #Pretrained model is loaded\n",
    "model.set_generation_params(duration=10) #Generation length is decided as 10 seconds\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[ #Description with new instrument is given to the model\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated, #Reference audio is given to the model\n",
    "    melody_sample_rate=sr, #Input sampling rate\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000) #Output audio is displayed\n",
    "\n",
    "output_path = 'Samples/Final/1' #Folder for saving the generated audios\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}.wav\"), output_cpu[0], 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8757a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is same with the previous block, except the loaded model is our final model\n",
    "model_name = 'with_submixes_25ep'\n",
    "model = MusicGen.get_pretrained(f'../audiocraft/checkpoints/{model_name}/')\n",
    "model.set_generation_params(duration=10)\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "output_path = 'Samples/Final/1'\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}.wav\"), output_cpu[0], 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d58b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This block is same with the previous block, except the loaded model is our final model\n",
    "model_name = 'with_submixes_description_25ep'\n",
    "model = MusicGen.get_pretrained(f'../audiocraft/checkpoints/{model_name}/')\n",
    "model.set_generation_params(duration=10)\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "output_path = 'Samples/Final/1'\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}.wav\"), output_cpu[0], 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb45ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba35427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second instrument group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = ('Trumpet','Cello','Fretless Bass') #New instruments are defined\n",
    "instruments = ', '.join(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d432d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'original' #Model name is defined (baseline model)\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-melody') #Pretrained model is loaded\n",
    "model.set_generation_params(duration=10) #Generation length is decided as 10 seconds\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[ #Description with new instrument is given to the model\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated, #Reference audio is given to the model\n",
    "    melody_sample_rate=sr, #Input sampling rate\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000) #Output audio is displayed\n",
    "\n",
    "output_path = 'Samples/Final/2' #Folder for saving the generated audios\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}.wav\"), output_cpu[0], 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is same with the previous block, except the loaded model is our final model\n",
    "model_name = 'with_submixes_25ep'\n",
    "model = MusicGen.get_pretrained(f'../audiocraft/checkpoints/{model_name}/')\n",
    "model.set_generation_params(duration=10)\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "output_path = 'Samples/Final/2'\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}.wav\"), output_cpu[0], 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9be67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is same with the previous block, except the loaded model is our final model\n",
    "model_name = 'with_submixes_description_25ep'\n",
    "model = MusicGen.get_pretrained(f'../audiocraft/checkpoints/{model_name}/')\n",
    "model.set_generation_params(duration=10)\n",
    "\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        f'Instruments: {instruments}. {description}'\n",
    "    ],\n",
    "    melody_wavs=aud_input_repeated,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "print(i)\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "output_path = 'Samples/Final/2'\n",
    "output_cpu = output[0].to('cpu')\n",
    "torchaudio.save(os.path.join(output_path,f\"{model_name}_{i}.wav\"), output_cpu[0], 32000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (audiocraft)",
   "language": "python",
   "name": "audiocraft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
