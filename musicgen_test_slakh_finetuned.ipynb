{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from transformers import AutoProcessor, MusicgenMelodyForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "slakh_path = \"/engram/naplab/shared/Slakh2100/slakh2100_flac_redux\"\n",
    "track_path = \"test/Track01881\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(os.path.join(slakh_path,track_path,\"mix.flac\"), sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a573fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b955dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for aud_file in [file for file in os.listdir(os.path.join(slakh_path,track_path,'stems')) if file.endswith('.flac')]:\n",
    "    print(aud_file)\n",
    "    aud, sr = librosa.load(os.path.join(slakh_path,track_path,'stems',aud_file), sr=None)\n",
    "    display(Audio(aud,rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f51d68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-melody\")\n",
    "model = MusicgenMelodyForConditionalGeneration.from_pretrained(\"facebook/musicgen-melody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4350d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/sd3705/music_gen_2024f/audiocraft_output_sd3705/xps/both_indv_mix/checkpoint.th\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # or 'cuda' if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43824d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f6b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aud_input = librosa.load(os.path.join(slakh_path,track_path,'stems','S01.flac'), sr=None)[0]\n",
    "aud_input = aud_input[int(sr*1.5):int(sr*11.5)]\n",
    "display(Audio(aud_input,rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_output = librosa.load(os.path.join(slakh_path,track_path,'stems','S02.flac'), sr=None)[0]\n",
    "aud_output = aud_output[int(sr*1.5):int(sr*11.5)]\n",
    "display(Audio(aud_output,rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    audio=torch.tensor(aud_input),\n",
    "    sampling_rate=sr,\n",
    "    text=[\"Acoustic Guitar\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "Audio(audio_values[0].numpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    audio=torch.tensor(aud_input),\n",
    "    sampling_rate=sr,\n",
    "    text=[\"add piano to the track\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542325c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "Audio(audio_values[0].numpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    audio=torch.tensor(aud_input),\n",
    "    sampling_rate=sr,\n",
    "    text=[\"piano, electro guitar\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5029bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "Audio(audio_values[0].numpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78093794",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    audio=torch.tensor(aud_input),\n",
    "    sampling_rate=sr,\n",
    "    text=[\"only piano\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "only_piano = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(only_piano[0].numpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_piano.squeeze().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b519ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_guitar = aud_input[:only_piano.shape[0]]\n",
    "#only_piano = only_piano.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd7d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(only_guitar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa284b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore(only_guitar).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(zscore(only_guitar), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bec624",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(zscore(only_piano)+zscore(only_guitar), rate=sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (s)",
   "language": "python",
   "name": "s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
