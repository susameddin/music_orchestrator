# General
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
project: Synesthesia
experiment: SFT_Q2A_ALL_VGG_MC4_dist_r16_ep10
output_dir: !ref /engram/naplab/users/xj2289/ckpts/project_synesthesia/Qwen2Audio

pretrained_model_name_or_path: Qwen/Qwen2-Audio-7B-Instruct 

# Data Config
audio_root: /engram/naplab/shared/VGGSound/audio
train_json: manifests/VGGSound/good/good_train_uni.json
label_distributions_json: manifests/VGGSound/label_distributions.json
neg_choices_by: distribution
n_choice: 4

# Dataset
train_data: !new:dataset.vggsound_clsmc.Qwen2AudioSFTRandomVGGSoundCLSMC
    manifest_path: !ref <train_json>
    data_root: !ref <audio_root>
    tokenizer: !ref <tokenizer>
    processor: !ref <processor>
    label_distributions_path: !ref <label_distributions_json>
    neg_choices_by: !ref <neg_choices_by>
    pos_choice_pos: random
    n_choice: !ref <n_choice>

valid_data: null
    
# Preprocessor
tokenizer: !apply:transformers.AutoTokenizer.from_pretrained
    pretrained_model_name_or_path: !ref <pretrained_model_name_or_path>

processor: !apply:transformers.AutoProcessor.from_pretrained
    pretrained_model_name_or_path: !ref <pretrained_model_name_or_path>

data_collator: !new:dataset.qwen2audio_utils.DataCollator
    tokenizer: !ref <tokenizer>

# LoRA
rank: 16
alpha: !ref <rank>
lora_config: !new:peft.LoraConfig
    r: !ref <rank>
    lora_alpha: !ref <alpha>
    target_modules: ['k_proj', 'v_proj', 'q_proj', 'out_proj', 'o_proj', 'fc1', 'fc2', 'value', 'gate_proj', 'up_proj', 'down_proj']
    lora_dropout: 0.05
    bias: none

# LLM
qwen: !apply:transformers.AutoModelForSeq2SeqLM.from_pretrained
    pretrained_model_name_or_path: Qwen/Qwen2-Audio-7B-Instruct
    device_map: cuda
    trust_remote_code: true

lora_qwen: !apply:peft.get_peft_model
    model: !ref <qwen>
    peft_config: !ref <lora_config>

# Training Config
bf16: true
optim: adamw_torch
learning_rate: 1.0e-4
lr_scheduler_type: cosine
warmup_ratio: 0.1

per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8

num_train_epochs: 1
save_strategy: steps
save_steps: 1000
save_safetensors: false
save_total_limit: 3
load_best_model_at_end: false
logging_steps: 100
report_to: wandb
resume_from_checkpoint: false
dataloader_num_workers: 4

train_config: !new:transformers.TrainingArguments
    run_name: !ref <experiment>
    output_dir: !ref <output_dir>
    bf16: !ref <bf16>
    optim: !ref <optim>
    learning_rate: !ref <learning_rate>
    lr_scheduler_type: !ref <lr_scheduler_type>
    warmup_ratio: !ref <warmup_ratio>
    per_device_train_batch_size: !ref <per_device_train_batch_size>
    per_device_eval_batch_size: !ref <per_device_eval_batch_size>
    gradient_accumulation_steps: !ref <gradient_accumulation_steps>
    num_train_epochs: !ref <num_train_epochs>
    save_strategy: !ref <save_strategy>
    save_steps: !ref <save_steps>
    save_safetensors: !ref <save_safetensors>
    save_total_limit: !ref <save_total_limit>
    load_best_model_at_end: !ref <load_best_model_at_end>
    logging_steps: !ref <logging_steps>
    report_to: !ref <report_to>
    evaluation_strategy: epoch
    remove_unused_columns: false
    dataloader_num_workers: !ref <dataloader_num_workers>
    resume_from_checkpoint: !ref <resume_from_checkpoint>
